{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "load and preprocess data based on 001."
      ],
      "metadata": {
        "id": "LKdVpvTsKZ8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2EmzajSXKe-P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 32\n",
        "FEATURE_DIM = 4\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "MIDI_ROOT = path\n",
        "EMBED_DIM = 128\n",
        "NUM_HEADS = 4\n",
        "FF_DIM = 256\n",
        "NUM_LAYERS = 2"
      ],
      "metadata": {
        "id": "W48TG86-Kgst"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def midi_to_note_vector(midi_file):\n",
        "    try:\n",
        "        pm = pretty_midi.PrettyMIDI(midi_file)\n",
        "        notes = []\n",
        "        for instrument in pm.instruments:\n",
        "            if instrument.is_drum:\n",
        "                continue\n",
        "            for note in instrument.notes:\n",
        "                notes.append([note.pitch / 128, note.velocity / 128, note.end - note.start, note.start])\n",
        "        notes = sorted(notes, key=lambda x: x[3])\n",
        "        vectors = []\n",
        "        for i in range(len(notes) - 1):\n",
        "            delta_time = notes[i+1][3] - notes[i][3]\n",
        "            vectors.append([notes[i][0], notes[i][1], notes[i][2], delta_time])\n",
        "            if len(vectors) == SEQ_LEN:\n",
        "                break\n",
        "        return np.array(vectors[:SEQ_LEN]) if len(vectors) == SEQ_LEN else None\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {midi_file} due to error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_midi_dataset(path):\n",
        "    data = []\n",
        "    for root, _, files in os.walk(path):\n",
        "        for file in files:\n",
        "            if file.endswith('.mid') or file.endswith('.midi'):\n",
        "                vec = midi_to_note_vector(os.path.join(root, file))\n",
        "                if vec is not None:\n",
        "                    data.append(vec)\n",
        "    return np.array(data, dtype=np.float32)"
      ],
      "metadata": {
        "id": "OwjEV4qQKj9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(layers.Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super().__init__()\n",
        "        self.pos_encoding = self.get_positional_encoding(sequence_length, embed_dim)\n",
        "\n",
        "    def get_positional_encoding(self, length, d_model):\n",
        "        pos = np.arange(length)[:, np.newaxis]\n",
        "        i = np.arange(d_model)[np.newaxis, :]\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "        angle_rads = pos * angle_rates\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "        return tf.constant(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
        "\n",
        "    def call(self, x):\n",
        "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n"
      ],
      "metadata": {
        "id": "JE_2XwoPKz1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_block(embed_dim, num_heads, ff_dim):\n",
        "    inputs = layers.Input(shape=(None, embed_dim))\n",
        "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
        "    x = layers.LayerNormalization()(inputs + attn_output)\n",
        "    ff_output = layers.Dense(ff_dim, activation='relu')(x)\n",
        "    ff_output = layers.Dense(embed_dim)(ff_output)\n",
        "    x = layers.LayerNormalization()(x + ff_output)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "\n",
        "def build_transformer(seq_len, feature_dim):\n",
        "    inputs = layers.Input(shape=(seq_len, feature_dim))\n",
        "    x = layers.Dense(EMBED_DIM)(inputs)\n",
        "    x = PositionalEncoding(seq_len, EMBED_DIM)(x)\n",
        "\n",
        "    for _ in range(NUM_LAYERS):\n",
        "        x = transformer_block(EMBED_DIM, NUM_HEADS, FF_DIM)(x)\n",
        "\n",
        "    outputs = layers.Dense(feature_dim)(x)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "Fxqc0tarLHW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_prediction(true_seq, pred_seq):\n",
        "    fig, axes = plt.subplots(FEATURE_DIM, 1, figsize=(10, 6))\n",
        "    for i in range(FEATURE_DIM):\n",
        "        axes[i].plot(true_seq[:, i], label='True', color='black')\n",
        "        axes[i].plot(pred_seq[:, i], label='Predicted', linestyle='dashed', color='blue')\n",
        "        axes[i].set_ylabel(f'Feature {i+1}')\n",
        "    axes[0].legend()\n",
        "    plt.suptitle(\"True vs Predicted Note Features\")\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_losses(losses):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(losses, label='Training Loss', color='green')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Transformer Training Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_transformer(model, dataset):\n",
        "    losses = []\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        idx = np.random.randint(0, len(dataset), BATCH_SIZE)\n",
        "        batch = dataset[idx]\n",
        "        x_input = batch[:, :-1, :]\n",
        "        y_target = batch[:, 1:, :]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(x_input, training=True)\n",
        "            loss = loss_fn(y_target, y_pred)\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        losses.append(loss.numpy())\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {loss.numpy():.4f}\")\n",
        "\n",
        "    plot_losses(losses)\n",
        "\n",
        "\n",
        "    sample = dataset[np.random.randint(len(dataset))]\n",
        "    x_in = sample[np.newaxis, :-1, :]\n",
        "    true_out = sample[1:, :]\n",
        "    pred_out = model(x_in, training=False)[0]\n",
        "    visualize_prediction(true_out, pred_out)\n",
        "\n",
        "\n",
        "dataset = load_midi_dataset(MIDI_ROOT)\n",
        "print(f\"Loaded {len(dataset)} MIDI samples.\")\n",
        "\n",
        "transformer_model = build_transformer(SEQ_LEN - 1, FEATURE_DIM)\n",
        "train_transformer(transformer_model, dataset)"
      ],
      "metadata": {
        "id": "9pLepEwmLI_9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}