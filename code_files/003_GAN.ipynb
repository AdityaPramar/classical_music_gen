{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "load and preprocess data based on 001."
      ],
      "metadata": {
        "id": "LKdVpvTsKZ8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2EmzajSXKe-P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LATENT_DIM = 100\n",
        "NOTE_LENGTH = 32\n",
        "FEATURE_DIM = 4\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1000\n",
        "MIDI_ROOT = path\n",
        "def midi_to_note_vector(midi_file):\n",
        "    try:\n",
        "        pm = pretty_midi.PrettyMIDI(midi_file)\n",
        "        notes = []\n",
        "        for instrument in pm.instruments:\n",
        "            if instrument.is_drum:\n",
        "                continue\n",
        "            for note in instrument.notes:\n",
        "                notes.append([note.pitch, note.velocity, note.end - note.start, note.start])\n",
        "        notes = sorted(notes, key=lambda x: x[3])\n",
        "        note_vectors = []\n",
        "        for i in range(len(notes) - 1):\n",
        "            delta_time = notes[i+1][3] - notes[i][3]\n",
        "            note_vectors.append([notes[i][0]/128, notes[i][1]/128, notes[i][2], delta_time])\n",
        "            if len(note_vectors) == NOTE_LENGTH:\n",
        "                break\n",
        "        return np.array(note_vectors[:NOTE_LENGTH]) if len(note_vectors) == NOTE_LENGTH else None\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {midi_file} due to error: {e}\")\n",
        "        return None\n",
        "def load_midi_dataset(path):\n",
        "    data = []\n",
        "    for root, _, files in os.walk(path):\n",
        "        for file in files:\n",
        "            if file.endswith('.mid') or file.endswith('.midi'):\n",
        "                vec = midi_to_note_vector(os.path.join(root, file))\n",
        "                if vec is not None:\n",
        "                    data.append(vec)\n",
        "    return np.array(data, dtype=np.float32)"
      ],
      "metadata": {
        "id": "W48TG86-Kgst"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Input(shape=(LATENT_DIM,)),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(NOTE_LENGTH * FEATURE_DIM),\n",
        "        layers.Reshape((NOTE_LENGTH, FEATURE_DIM)),\n",
        "        layers.Activation('sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Input(shape=(NOTE_LENGTH, FEATURE_DIM)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def visualize_output(generator):\n",
        "    noise = tf.random.normal([1, LATENT_DIM])\n",
        "    generated = generator(noise, training=False)[0]\n",
        "    plt.imshow(generated.numpy().T, aspect='auto', cmap='viridis')\n",
        "    plt.title(\"Generated Note Sequence\")\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.ylabel(\"Features\")\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OwjEV4qQKj9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_gan(generator, discriminator, dataset):\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "    gen_opt = tf.keras.optimizers.Adam(1e-4)\n",
        "    disc_opt = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "    gen_losses = []\n",
        "    disc_losses = []\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(real_batch):\n",
        "        noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            fake_batch = generator(noise, training=True)\n",
        "            real_output = discriminator(real_batch, training=True)\n",
        "            fake_output = discriminator(fake_batch, training=True)\n",
        "            gen_loss = loss_fn(tf.ones_like(fake_output), fake_output)\n",
        "            disc_loss = loss_fn(tf.ones_like(real_output), real_output) + \\\n",
        "                        loss_fn(tf.zeros_like(fake_output), fake_output)\n",
        "        grads_g = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        grads_d = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "        gen_opt.apply_gradients(zip(grads_g, generator.trainable_variables))\n",
        "        disc_opt.apply_gradients(zip(grads_d, discriminator.trainable_variables))\n",
        "        return gen_loss, disc_loss\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        idx = np.random.randint(0, dataset.shape[0], BATCH_SIZE)\n",
        "        real_batch = dataset[idx]\n",
        "        gen_loss, disc_loss = train_step(real_batch)\n",
        "\n",
        "        gen_losses.append(gen_loss.numpy())\n",
        "        disc_losses.append(disc_loss.numpy())\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}: Gen Loss={gen_loss.numpy():.4f}, Disc Loss={disc_loss.numpy():.4f}\")\n",
        "            visualize_output(generator)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(gen_losses, label='Generator Loss', color='blue')\n",
        "    plt.plot(disc_losses, label='Discriminator Loss', color='red')\n",
        "    plt.title('Epoch vs Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "dataset = load_midi_dataset(MIDI_ROOT)\n",
        "print(f\"Loaded {len(dataset)} MIDI samples.\")\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "train_gan(generator, discriminator, dataset)"
      ],
      "metadata": {
        "id": "JE_2XwoPKz1I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}